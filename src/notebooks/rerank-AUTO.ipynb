{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2ad666-a36a-4311-b5cc-7d2e13e77d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ed9951-847d-465e-87b8-e1b736dea5f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c931c6b-fcc7-49ed-b87d-1b179a4b27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import os, sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "\n",
    "sys.path.append('../../src')\n",
    "from models.dpr import VanillaDPR\n",
    "from arguments import get_rerank_parser\n",
    "from util.dataset import get_rerank_dataset\n",
    "from util.util import MixedPrecisionManager, query_tokenizer, doc_tokenizer, hugface_models, set_seed, trec_eval, query_tokenizer_paragraph, document_tokenizer_paragraph\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1763daab-614d-4ff6-8346-11e7c21af66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_agg(score_matrix, query_reps, doc_reps, args):\n",
    "    if args.score_agg == \"colbert\":\n",
    "        max_input, max_indx = torch.max(scores, dim=1)\n",
    "        return torch.mean(max_input).item()\n",
    "    \n",
    "    elif args.score_agg == \"vector_rrf\" :\n",
    "        final_query_rep = torch.mean(query_reps, dim =0, keepdim=True)\n",
    "        \n",
    "        rank_matrix = torch.zeros(score_matrix.shape)\n",
    "        _argsort = torch.argsort(score_matrix, descending=True)\n",
    "        for row in range(len(_argsort)):\n",
    "            for col in range(len(_argsort[row])):\n",
    "                indx = _argsort[row][col]\n",
    "                rank_matrix[row][indx] = col + 1\n",
    "            \n",
    "        rrf = torch.add(rank_matrix, 60)   \n",
    "        rrf = rrf.pow(-1)\n",
    "        rrf = torch.mean(rrf, dim=0, keepdim=True)\n",
    "        rrf = rrf.to(args.device)\n",
    "        final_doc_rep = rrf.mm(doc_reps)\n",
    "        return F.cosine_similarity(final_query_rep, final_doc_rep).item()\n",
    "    \n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a83579-136e-45ec-a70e-5e5782517b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(args):\n",
    "    query_dataset, rerank_document_dataset, run = get_rerank_dataset(args)  \n",
    "    \n",
    "    query_loader = torch.utils.data.DataLoader(query_dataset,\n",
    "                                                   batch_size=args.batch_size,\n",
    "                                                   drop_last=False,\n",
    "                                                   shuffle=False)\n",
    "    \n",
    "    document_loader = torch.utils.data.DataLoader(rerank_document_dataset,\n",
    "                                                      batch_size=args.batch_size, \n",
    "                                                      drop_last=False)\n",
    "    \n",
    "    return query_loader, document_loader, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae4cc126-22d1-403a-93c4-22bf2d346e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH='/work/snaseri_umass_edu/'\n",
    "params = f\"\"\"--mode AUTO-HITL --seed 42 --model_name xlm-roberta-base --output_dir {BASE_PATH}/better_P3/experiments/BetterRerankerS1/runs --checkpoint {BASE_PATH}/multi_lang_dpr/checkpoints/msmarco/dpr_baseline_msmaroco_xlmr_multi_lang/ar_zh_ru/checkpoint_at_0.pth --query_maxlen 32 --doc_maxlen 180 --rerank_topK 1000 --collection_file {BASE_PATH}/better_P3/data/BETTER_PHASE3_COMBO_ARABIC_FARSI_RUSSIAN/combined-corpus.jl --task_file {BASE_PATH}/better_P3/data/BETTER_PHASE3_COMBO_ARABIC_FARSI_RUSSIAN/ir-auto-hitl-eval-tasks.json --test_qrels {BASE_PATH}/better_P3/data/BETTER_PHASE3_COMBO_ARABIC_FARSI_RUSSIAN/IR-relevance-assessments.qrels.GALAGO --test_run {BASE_PATH}/better_P3/data/BETTER_PHASE3_COMBO_ARABIC_FARSI_RUSSIAN/62e171cedebb2f0d2619f2f6.FINAL.out\"\"\".replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3550da-96a5-4d7a-b785-47edefedcecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_rerank_parser()\n",
    "args = parser.parse_args(params.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "531520af-f007-480c-a35a-f54b978f2f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.score_agg = \"colbert\"\n",
    "args.batch_size = 1\n",
    "args.stride = 10\n",
    "args.rrf_k = 60\n",
    "set_seed(args.seed)\n",
    "args.device = torch.cuda.current_device()\n",
    "os.makedirs(args.output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb6e7e9-68fd-4e80-bc00-73f1971440d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "_, tokenizer_class, model_class = hugface_models(args.model_name)\n",
    "query_encoder = model_class.from_pretrained(args.model_name)\n",
    "doc_encoder = model_class.from_pretrained(args.model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "model = VanillaDPR(query_encoder, doc_encoder, args)\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8663e816-2ddc-4800-aa4c-198188a6588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoint\n",
    "if args.checkpoint:\n",
    "    state_dict = torch.load(os.path.join(args.checkpoint))[\"model_state_dict\"]\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b3ffa11-1197-40f8-b44b-eba0d5690586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading collection: 100%|████████████████████████████████████████████████████████████████████████████████| 864971/864971 [01:11<00:00, 12086.05it/s]\n",
      "loading qrel data: 100%|████████████████████████████████████████████████████████████████████████████████████| 3903/3903 [00:00<00:00, 571850.65it/s]\n",
      "loading run data: 100%|███████████████████████████████████████████████████████████████████████████████████| 54000/54000 [00:00<00:00, 996767.18it/s]\n"
     ]
    }
   ],
   "source": [
    "query_loader, document_loader, baseline_run = get_datasets(args)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab393df7-7c5e-4701-bebe-30ebb4bf8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "rerank_run = defaultdict(dict)\n",
    "METRIC = 'map'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a536533-9d64-45d7-8462-d57637953210",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encode rerank queries:   0%|                                                                                                 | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encode rerank queries:  11%|█████████▉                                                                               | 6/54 [00:01<00:06,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "15\n",
      "22\n",
      "18\n",
      "16\n",
      "21\n",
      "22\n",
      "21\n",
      "23\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encode rerank queries:  39%|██████████████████████████████████▏                                                     | 21/54 [00:01<00:01, 26.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "24\n",
      "30\n",
      "33\n",
      "25\n",
      "27\n",
      "26\n",
      "14\n",
      "18\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encode rerank queries:  50%|████████████████████████████████████████████                                            | 27/54 [00:01<00:00, 33.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "13\n",
      "15\n",
      "13\n",
      "15\n",
      "15\n",
      "19\n",
      "14\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encode rerank queries:  72%|███████████████████████████████████████████████████████████████▌                        | 39/54 [00:01<00:00, 43.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "12\n",
      "13\n",
      "13\n",
      "11\n",
      "11\n",
      "13\n",
      "15\n",
      "15\n",
      "14\n",
      "14\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encode rerank queries: 100%|████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 27.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "19\n",
      "17\n",
      "17\n",
      "20\n",
      "18\n",
      "18\n",
      "17\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    qreps = {}\n",
    "    for item in tqdm(query_loader, desc=f'encode rerank queries'):\n",
    "        qid = item['qid'][0]  \n",
    "        qtext = item['qtext'][0]\n",
    "        q_chunck_ids, q_chunk_mask = query_tokenizer_paragraph(qtext, args, tokenizer)\n",
    "        q_reps = model.query(q_chunck_ids, q_chunk_mask)\n",
    "        qreps[qid] = q_reps.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e14e2adc-f9ca-4fae-af9f-1b18b7e532d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encode rerank documents: 100%|██████████████████████████████████████████████████████████████████████████████████| 7859/7859 [02:37<00:00, 49.79it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    dreps = {}\n",
    "    for item in tqdm(document_loader, desc=f'encode rerank documents'):\n",
    "        docid, doctext = item   \n",
    "        docid = docid[0]\n",
    "        doctext = doctext[0]\n",
    "        d_chunk_ids, d_chunk_mask = document_tokenizer_paragraph(doctext, args, tokenizer)\n",
    "        d_reps = model.doc(d_chunk_ids, d_chunk_mask)\n",
    "        dreps[docid] = d_reps.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d127965d-a44d-427d-96cf-eafbfa15627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:05<00:00,  9.66it/s]\n"
     ]
    }
   ],
   "source": [
    "rerank_run = defaultdict(dict)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for qid in tqdm(qreps):\n",
    "        rank_list = baseline_run[qid]\n",
    "        query_rep = qreps[qid].to(args.device)\n",
    "        for docid in rank_list:\n",
    "            document_rep = dreps[docid].to(args.device)\n",
    "            scores = model.score(query_rep, document_rep)\n",
    "            score = score_agg(model.score(query_rep, document_rep), query_rep, document_rep, args)            \n",
    "            rerank_run[qid][docid] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5e46ed6-3914-4bc4-b2ca-5e988e9bca79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 424.83it/s]\n"
     ]
    }
   ],
   "source": [
    "runf = os.path.join(args.output_dir, f'AUTO-HITL-DPR-Reranked_info_task_title-task_stmt-task_narr-task_docs_segment_text-req_text-req_docs_segment_text.run')\n",
    "\n",
    "with open(runf, 'wt') as runfile:\n",
    "    for qid in tqdm(rerank_run):\n",
    "        scores = list(sorted(rerank_run[qid].items(), key=lambda x: (x[1], x[0]), reverse=True))\n",
    "        for i, (did, score) in enumerate(scores):\n",
    "            runfile.write(f'{qid} 0 {did} {i+1} {score} run\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "969dfc3c-bcfa-4be0-bc03-518649748d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_list = {}\n",
    "for qid in baseline_run:\n",
    "    ranklist = list(sorted(baseline_run[qid].items(), key=lambda x: (x[1], x[0]), reverse=True))\n",
    "    baseline_list.setdefault(qid, [])\n",
    "    for retdoc in ranklist:\n",
    "        baseline_list[qid].append(retdoc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21366c91-6052-40f8-8fcd-de0abc7ee165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 98.88it/s]\n"
     ]
    }
   ],
   "source": [
    "fusion_run = defaultdict(dict)\n",
    "for qid in tqdm(rerank_run):\n",
    "    rerank_list = list(sorted(rerank_run[qid].items(), key=lambda x: (x[1], x[0]), reverse=True))\n",
    "    for i in range(len(rerank_list)):\n",
    "        did = rerank_list[i][0]\n",
    "        rerank_at = i + 1\n",
    "        baseline_at = baseline_list[qid].index(did) + 1\n",
    "        fused_score = (1/(args.rrf_k + rerank_at)) + (1/(args.rrf_k + baseline_at))\n",
    "        fusion_run[qid][did] = fused_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62a2ac6e-8307-4a63-85a2-8f4008bc546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_file = os.path.join(args.output_dir, f'Fusion_AUTO-HITL-DPR-Reranked_info_task_title-task_stmt-task_narr-task_docs_segment_text-req_text-req_docs_segment_text_Baseline_rrf-k_{args.rrf_k}.run')\n",
    "with open(fusion_file, 'wt') as runfile:\n",
    "    for qid in fusion_run:\n",
    "        dummy_score = 100000\n",
    "        fused_scores = list(sorted(fusion_run[qid].items(), key=lambda x: (x[1], x[0]), reverse=True))\n",
    "        for i, (did, score) in enumerate(fused_scores):\n",
    "            runfile.write(f'{qid} 0 {did} {i+1} {dummy_score} run\\n')\n",
    "            dummy_score -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8510742-d34d-48e7-9c38-efd6b2428f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b3df8c-cdfe-4357-9b76-40a181b9fa42",
   "metadata": {},
   "source": [
    "# RoundRobin Fusion of Arabic and Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c3d0a-ac8b-486d-8e76-59d2dba6988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_run = read_run(\"/work/snaseri_umass_edu/better_P3/data/BETTER_PHASE3_COMBO_ARABIC_FARSI_RUSSIAN/runfiles/62e171cedebb2f0d2619f2f6.arabic.Request.RERANKED.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603cea5-787d-4ec2-86b4-d0ce5555a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_run = read_run(\"/work/snaseri_umass_edu/better_P3/data/BETTER_PHASE3_COMBO_ARABIC_FARSI_RUSSIAN/runfiles/62e171cedebb2f0d2619f2f6.russian.Request.RERANKED.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b49fd-5d99-4255-8546-a0189bb98ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundrobin(*iterables):\n",
    "    \"roundrobin('ABC', 'D', 'EF') --> A D E B F C\"\n",
    "    # Recipe credited to George Sakkis\n",
    "    pending = len(iterables)\n",
    "    nexts = cycle(iter(it).next for it in iterables)\n",
    "    while pending:\n",
    "        try:\n",
    "            for next in nexts:\n",
    "                yield next()\n",
    "        except StopIteration:\n",
    "            pending -= 1\n",
    "            nexts = cycle(islice(nexts, pending))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d89432-b303-4b28-804d-60fc82489cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_robin_run = {}\n",
    "\n",
    "for q in tqdm(arabic_run):\n",
    "    ar_rank_list = list(sorted(arabic_run[q].items(), key=lambda x: x[1], reverse=True))\n",
    "    ru_rank_list = list(sorted(russian_run[q].items(), key=lambda x: x[1], reverse=True))\n",
    "    round_robin_run.setdefault(q,[])\n",
    "    for item in zip(ar_rank_list, ru_rank_list):\n",
    "        round_robin_run[q].append(item[0][0])\n",
    "        round_robin_run[q].append(item[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942f205-60d1-4a91-bcb5-7db52e8ea8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 1000\n",
    "round_robin_file= os.path.join(args.output_dir, f'round_robin_ar_ru_baseline.run')\n",
    "with open(round_robin_file, 'wt') as runfile:\n",
    "    for qid in round_robin_run:\n",
    "        dummy_score = 100000\n",
    "        rank = 1\n",
    "        for did in round_robin_run[qid][:topk]:\n",
    "            runfile.write(f'{qid} 0 {did} {rank} {dummy_score} run\\n')\n",
    "            dummy_score -= 1\n",
    "            rank += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-match",
   "language": "python",
   "name": "gen-match"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c931c6b-fcc7-49ed-b87d-1b179a4b27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import torch\n",
    "import os, sys\n",
    "from models.dpr import VanillaDPR\n",
    "from arguments import get_rerank_parser\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "\n",
    "from util.dataset import get_rerank_dataset\n",
    "from util.util import MixedPrecisionManager, query_tokenizer, doc_tokenizer, hugface_models, set_seed, trec_eval, query_tokenizer_paragraph, document_tokenizer_paragraph\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1763daab-614d-4ff6-8346-11e7c21af66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_agg(score_matrix, query_reps, doc_reps, args):\n",
    "    if args.score_agg == \"colbert\":\n",
    "        max_input, max_indx = torch.max(scores, dim=1)\n",
    "        return torch.mean(max_input).item()\n",
    "    \n",
    "    elif args.score_agg == \"vector_rrf\" :\n",
    "        final_query_rep = torch.mean(query_reps, dim =0, keepdim=True)\n",
    "        \n",
    "        rank_matrix = torch.zeros(score_matrix.shape)\n",
    "        _argsort = torch.argsort(score_matrix, descending=True)\n",
    "        for row in range(len(_argsort)):\n",
    "            for col in range(len(_argsort[row])):\n",
    "                indx = _argsort[row][col]\n",
    "                rank_matrix[row][indx] = col + 1\n",
    "            \n",
    "        rrf = torch.add(rank_matrix, 60)   \n",
    "        rrf = rrf.pow(-1)\n",
    "        rrf = torch.mean(rrf, dim=0, keepdim=True)\n",
    "        rrf = rrf.to(args.device)\n",
    "        final_doc_rep = rrf.mm(doc_reps)\n",
    "        return F.cosine_similarity(final_query_rep, final_doc_rep).item()\n",
    "    \n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a83579-136e-45ec-a70e-5e5782517b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(args):\n",
    "    query_dataset, rerank_document_dataset, run = get_rerank_dataset(args)  \n",
    "    \n",
    "    query_loader = torch.utils.data.DataLoader(query_dataset,\n",
    "                                                   batch_size=args.batch_size,\n",
    "                                                   drop_last=False,\n",
    "                                                   shuffle=False)\n",
    "    \n",
    "    document_loader = torch.utils.data.DataLoader(rerank_document_dataset,\n",
    "                                                      batch_size=args.batch_size, \n",
    "                                                      drop_last=False)\n",
    "    \n",
    "    return query_loader, document_loader, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4cc126-22d1-403a-93c4-22bf2d346e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH='/work/snaseri_umass_edu/'\n",
    "params = f\"\"\"--mode AUTO --seed 42 --model_name xlm-roberta-base --output_dir {BASE_PATH}/better_P3/experiments/BetterRerankerS1/runs --query_maxlen 32 --doc_maxlen 180 --rerank_topK 1000 --collection_file {BASE_PATH}/better_P3/data/BETTER_PHASE3_COMBO_ARABIC_FARSI_RUSSIAN/combined-corpus.jl --task_file {BASE_PATH}/better_P3/data/BETTER_PHASE3_COMBO_ARABIC_FARSI_RUSSIAN/62e171cedebb2f0d2619f2f6.analytic_tasks.json --test_qrels {BASE_PATH}/better_P3/data/BETTER_PHASE3_COMBO_ARABIC_FARSI_RUSSIAN/IR-relevance-assessments.qrels.GALAGO --test_run {BASE_PATH}/better_P3/experiments/BetterRerankerS1/runs/62e171cedebb2f0d2619f2f6.FINAL.out\"\"\".replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f3550da-96a5-4d7a-b785-47edefedcecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_rerank_parser()\n",
    "args = parser.parse_args(params.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4cccee-fb4b-41b2-ac11-c33aff1dd29d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03319501876831055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Downloading config.json",
       "rate": null,
       "total": 665,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b01df0dbe58438b995745f9852b7088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02792668342590332,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Downloading pytorch_model.bin",
       "rate": null,
       "total": 501039451,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0f92e3b9c04f2185c59c9676a44e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at castorini/ance-msmarco-passage were not used when initializing RobertaModel: ['embeddingHead.weight', 'embeddingHead.bias', 'norm.weight', 'norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"castorini/ance-msmarco-passage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6654ac30-9ce9-416c-818d-efef5f840cb6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.027773618698120117,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Downloading tokenizer_config.json",
       "rate": null,
       "total": 1045,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5c22b2f13740f7b94e42c5e45937f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.027106285095214844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Downloading vocab.json",
       "rate": null,
       "total": 898822,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54cec1b5b5b45beb5e051caafff169f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.026322126388549805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Downloading merges.txt",
       "rate": null,
       "total": 456318,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb366fa163e430090a11f71bcab94bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.027194499969482422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 33,
       "postfix": null,
       "prefix": "Downloading special_tokens_map.json",
       "rate": null,
       "total": 772,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26b617381724d458301da0b996100b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"castorini/ance-msmarco-passage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65968b0f-d394-445c-9962-d31551469984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "531520af-f007-480c-a35a-f54b978f2f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at castorini/ance-msmarco-passage were not used when initializing RobertaModel: ['embeddingHead.weight', 'embeddingHead.bias', 'norm.weight', 'norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at castorini/ance-msmarco-passage were not used when initializing RobertaModel: ['embeddingHead.weight', 'embeddingHead.bias', 'norm.weight', 'norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "args.score_agg = \"colbert\"\n",
    "args.batch_size = 1\n",
    "args.stride = 10\n",
    "args.rrf_k = 60\n",
    "set_seed(args.seed)\n",
    "args.device = torch.cuda.current_device()\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# _, tokenizer_class, model_class = hugface_models(args.model_name)\n",
    "query_encoder = AutoModel.from_pretrained(\"castorini/ance-msmarco-passage\")\n",
    "doc_encoder = AutoModel.from_pretrained(\"castorini/ance-msmarco-passage\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"castorini/ance-msmarco-passage\")\n",
    "model = VanillaDPR(query_encoder, doc_encoder, args)\n",
    "model = model.to(args.device)\n",
    "\n",
    "# # load checkpoint\n",
    "# if args.checkpoint:\n",
    "#     state_dict = torch.load(os.path.join(args.checkpoint))[\"model_state_dict\"]\n",
    "#     model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b3ffa11-1197-40f8-b44b-eba0d5690586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading collection: 100%|███████████████████████████████████████████████████████████████████| 864971/864971 [01:11<00:00, 12099.87it/s]\n",
      "loading qrel data: 100%|███████████████████████████████████████████████████████████████████████| 3903/3903 [00:00<00:00, 577397.31it/s]\n",
      "loading run data: 100%|██████████████████████████████████████████████████████████████████████| 54000/54000 [00:00<00:00, 928369.36it/s]\n"
     ]
    }
   ],
   "source": [
    "query_loader, document_loader, baseline_run = get_datasets(args)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab393df7-7c5e-4701-bebe-30ebb4bf8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "rerank_run = defaultdict(dict)\n",
    "METRIC = 'map'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a536533-9d64-45d7-8462-d57637953210",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encode rerank queries: 100%|███████████████████████████████████████████████████████████████████████████| 54/54 [00:02<00:00, 18.44it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    qreps = {}\n",
    "    for item in tqdm(query_loader, desc=f'encode rerank queries'):\n",
    "        qid = item['qid'][0]  \n",
    "        qtext = item['qtext'][0]\n",
    "        q_chunck_ids, q_chunk_mask = query_tokenizer_paragraph(qtext, args, tokenizer)\n",
    "        q_reps = model.query(q_chunck_ids, q_chunk_mask)\n",
    "        qreps[qid] = q_reps.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e14e2adc-f9ca-4fae-af9f-1b18b7e532d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encode rerank documents: 100%|█████████████████████████████████████████████████████████████████████| 7859/7859 [06:08<00:00, 21.31it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    dreps = {}\n",
    "    for item in tqdm(document_loader, desc=f'encode rerank documents'):\n",
    "        docid, doctext = item   \n",
    "        docid = docid[0]\n",
    "        doctext = doctext[0]\n",
    "        d_chunk_ids, d_chunk_mask = document_tokenizer_paragraph(doctext, args, tokenizer)\n",
    "        d_reps = model.doc(d_chunk_ids, d_chunk_mask)\n",
    "        dreps[docid] = d_reps.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d127965d-a44d-427d-96cf-eafbfa15627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:06<00:00,  7.98it/s]\n"
     ]
    }
   ],
   "source": [
    "rerank_run = defaultdict(dict)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for qid in tqdm(qreps):\n",
    "        rank_list = baseline_run[qid]\n",
    "        query_rep = qreps[qid].to(args.device)\n",
    "        for docid in rank_list:\n",
    "            document_rep = dreps[docid].to(args.device)\n",
    "            scores = model.score(query_rep, document_rep)\n",
    "            score = score_agg(model.score(query_rep, document_rep), query_rep, document_rep, args)            \n",
    "            rerank_run[qid][docid] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5e46ed6-3914-4bc4-b2ca-5e988e9bca79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 431.43it/s]\n"
     ]
    }
   ],
   "source": [
    "runf = os.path.join(args.output_dir, f'DPR-Reranked_with_eng2eng_model.run')\n",
    "\n",
    "with open(runf, 'wt') as runfile:\n",
    "    for qid in tqdm(rerank_run):\n",
    "        scores = list(sorted(rerank_run[qid].items(), key=lambda x: (x[1], x[0]), reverse=True))\n",
    "        for i, (did, score) in enumerate(scores):\n",
    "            runfile.write(f'{qid} 0 {did} {i+1} {score} run\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "969dfc3c-bcfa-4be0-bc03-518649748d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_list = {}\n",
    "for qid in baseline_run:\n",
    "    ranklist = list(sorted(baseline_run[qid].items(), key=lambda x: (x[1], x[0]), reverse=True))\n",
    "    baseline_list.setdefault(qid, [])\n",
    "    for retdoc in ranklist:\n",
    "        baseline_list[qid].append(retdoc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21366c91-6052-40f8-8fcd-de0abc7ee165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 99.54it/s]\n"
     ]
    }
   ],
   "source": [
    "fusion_run = defaultdict(dict)\n",
    "for qid in tqdm(rerank_run):\n",
    "    rerank_list = list(sorted(rerank_run[qid].items(), key=lambda x: (x[1], x[0]), reverse=True))\n",
    "    for i in range(len(rerank_list)):\n",
    "        did = rerank_list[i][0]\n",
    "        rerank_at = i + 1\n",
    "        baseline_at = baseline_list[qid].index(did) + 1\n",
    "        fused_score = (1/(args.rrf_k + rerank_at)) + (1/(args.rrf_k + baseline_at))\n",
    "        fusion_run[qid][did] = fused_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62a2ac6e-8307-4a63-85a2-8f4008bc546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_file = os.path.join(args.output_dir, f'Fusion_DPR_with_eng2eng_model-Reranker_Baseline_rrf-k_{args.rrf_k}.run')\n",
    "with open(fusion_file, 'wt') as runfile:\n",
    "    for qid in fusion_run:\n",
    "        dummy_score = 100000\n",
    "        fused_scores = list(sorted(fusion_run[qid].items(), key=lambda x: (x[1], x[0]), reverse=True))\n",
    "        for i, (did, score) in enumerate(fused_scores):\n",
    "            runfile.write(f'{qid} 0 {did} {i+1} {dummy_score} run\\n')\n",
    "            dummy_score -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b3df8c-cdfe-4357-9b76-40a181b9fa42",
   "metadata": {},
   "source": [
    "# RoundRobin Fusion of Arabic and Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c3d0a-ac8b-486d-8e76-59d2dba6988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_run = read_run(\"/work/snaseri_umass_edu/better_P3/data/BETTER_PHASE3_COMBO_ARABIC_FARSI_RUSSIAN/runfiles/62e171cedebb2f0d2619f2f6.arabic.Request.RERANKED.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603cea5-787d-4ec2-86b4-d0ce5555a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_run = read_run(\"/work/snaseri_umass_edu/better_P3/data/BETTER_PHASE3_COMBO_ARABIC_FARSI_RUSSIAN/runfiles/62e171cedebb2f0d2619f2f6.russian.Request.RERANKED.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b49fd-5d99-4255-8546-a0189bb98ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundrobin(*iterables):\n",
    "    \"roundrobin('ABC', 'D', 'EF') --> A D E B F C\"\n",
    "    # Recipe credited to George Sakkis\n",
    "    pending = len(iterables)\n",
    "    nexts = cycle(iter(it).next for it in iterables)\n",
    "    while pending:\n",
    "        try:\n",
    "            for next in nexts:\n",
    "                yield next()\n",
    "        except StopIteration:\n",
    "            pending -= 1\n",
    "            nexts = cycle(islice(nexts, pending))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d89432-b303-4b28-804d-60fc82489cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_robin_run = {}\n",
    "\n",
    "for q in tqdm(arabic_run):\n",
    "    ar_rank_list = list(sorted(arabic_run[q].items(), key=lambda x: x[1], reverse=True))\n",
    "    ru_rank_list = list(sorted(russian_run[q].items(), key=lambda x: x[1], reverse=True))\n",
    "    round_robin_run.setdefault(q,[])\n",
    "    for item in zip(ar_rank_list, ru_rank_list):\n",
    "        round_robin_run[q].append(item[0][0])\n",
    "        round_robin_run[q].append(item[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942f205-60d1-4a91-bcb5-7db52e8ea8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 1000\n",
    "round_robin_file= os.path.join(args.output_dir, f'round_robin_ar_ru_baseline.run')\n",
    "with open(round_robin_file, 'wt') as runfile:\n",
    "    for qid in round_robin_run:\n",
    "        dummy_score = 100000\n",
    "        rank = 1\n",
    "        for did in round_robin_run[qid][:topk]:\n",
    "            runfile.write(f'{qid} 0 {did} {rank} {dummy_score} run\\n')\n",
    "            dummy_score -= 1\n",
    "            rank += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-match",
   "language": "python",
   "name": "gen-match"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
